---
title: "ML_Project"
author: "Concillia Mpofu"
date: "2022-12-04"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}

library(ISLR2)
library(tidyverse)
library(boot)
```

Unlike other models ran for this data set, in this model i used the data set without dummy variables because of the limitation of R variable selection couldn't be done efficiently. 

```{r}
set.seed(12345)
#Loading the data without spliting it into training and test sampla
H1B_logit <-read_csv('../Data/H1B_logit.csv')

```
```{r, include=FALSE}
#Running the general linear model 

library(boot)
glm <- glm(CASE_STATUS ~ ., family = binomial(link = "logit"), data=H1B_logit)
```

```{r}
#Summary output of the glm
summary(glm)
```


```{r, include=FALSE}
#Model with the cross validation method boot strapping method. 

set.seed(123)
cv_result <- cv.glm(data = H1B_logit, glmfit=glm, K=10)
```


```{r}
#Mse = 0.03517
set.seed(123)
cv_result$delta[1]

```

Th model has a very low mean squared error. In running the model we initially did a train and test split becuase the split will contain other factor variables that will not be found in the test data especially in the Country, income and Current Visa Status variables. So we ended up excluding all the countries that appeared less than 100. Some of the data may have been outliers who may just increase the variances and decrease the predicting power of the model. 



