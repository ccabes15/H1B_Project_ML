---
title: "H1B - Ridge/Lasso"
author: "Jeremy Joy"
date: "2022-12-04"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r include=FALSE}
library(tidyverse)
library(broom)
library(janitor)
library(glmnet)
library(leaps)
library(tidymodels)
```

### Loading Training and Testing Data

```{r message=FALSE, warning=FALSE}
H1B_dummies_Train <- read_csv("../Data/H1B_Train_Dummies.csv")
H1B_dummies_Test <- read_csv("../Data/H1B_Test_Dummies.csv")
```

Note: The data includes dummy variables for all categorical variables (PW_SKILL_LEVEL, WAGE_OFFER_UNIT_OF_PAY, MINIMUM_EDUCATION, COUNTRY_OF_CITIZENSHIP, CLASS_OF_ADMISSION, FOREIGN_WORKER_EDUCATION, FOREIGN_WORKER_ED_INST_US, FOREIGN_WORKER_REQ_EXPERIENCE, FOREIGN_WORKER_EXP_WITH_EMPL). This was necessary so that the cv.glmnet() function would work for both Ridge and Lasso regression. It seemed to have an issue handling categorical variables as factors. 

H1B Training Data - Has 3,510 observations with 162 predictor variables (including dummies)
H1B Testing Data - Has 1,505 observations 

### Getting Training and Testing Design Matrices and Response Vectors

```{r}
x.train.dummies <- as.matrix(H1B_dummies_Train[,3:ncol(H1B_dummies_Train)])
y.train.dummies <- as.matrix(H1B_dummies_Train[,2])

x.test.dummies <- as.matrix(H1B_dummies_Test[,3:ncol(H1B_dummies_Test)])
y.test.dummies <- as.matrix(H1B_dummies_Test[,2])

```

### Running Ridge Regression

Ridge regression seems beneficial for this data due to the high number of predictor variables and because it is a shrinkage method that is useful in reducing multicollinearity as well as variance between estimates. 

```{r}
train_rr_dummies <- glmnet(x.train.dummies, as.factor(y.train.dummies), alpha=0, family = "binomial")
plot(train_rr_dummies)
```

Here we can see that as the L1 norm (gamma) decreases more parameters get closer to zero.

```{r}
plot(train_rr_dummies, xvar = "lambda")
```

In this plot we can see that as lambda increases the parameters get closer to zero and the weight of the penality for larger coefficents increases. 

```{r}
set.seed(123)
rr_cv_dummies <- cv.glmnet(x.train.dummies, as.factor(y.train.dummies), alpha=0, family= "binomial")
rr_cv_dummies
```

Here we can see that lambda.min is 0.017 and lambda.1se is 0.021. Let's take a look at the cross-validation curve. 

```{r}
plot(rr_cv_dummies)
```

In the plot we can clearly see that as lambda increases the Binomial Deviance increases. Notice the most left dashed line corresponds to lambda min and the other dashed line corresponds to lambda.1se. No coefficients or variables were eliminated from this model. 

### Finding Prediction MSE and Classification Rate for Ridge

```{r}
pred_test_rr_dummies <- bind_cols(predict(rr_cv_dummies, newx = x.test.dummies, s = "lambda.1se", type="response"),
                      predict(rr_cv_dummies, newx = x.test.dummies, s = "lambda.min", type="response"))

round(colMeans((pred_test_rr_dummies - y.test.dummies)^2), digits = 2)

Predicted.rr.dummies <- ifelse(pred_test_rr_dummies >= 0.5, 1, 0)[,1]
table(H1B_dummies_Test$CASE_STATUS, Predicted.rr.dummies)

class_rate1 = (563+645)/(563+186+111+645)

1- class_rate1
```

The RMSE for Ridge regression using our data was 0.14 and the error classification rate was 19.7%

### Running Lasso Regression

Lasso regression seems like an even better variation of ridge regression to use because ridge regression does not shrink parameters to zero. Our dataset including the dummy variables seems especially suited for LASSO as it has high dimension (a lot of predictors) and a good amount of correlation. Using LAsso, we can more easily identify the variables that are most strongly associated with H1B Visa approval.  

```{r}
train_lr_dummies <- glmnet(x.train.dummies, as.factor(y.train.dummies), family = "binomial")
plot(train_lr_dummies)
```

Here we can see that as the L1 norm (gamma) decreases the number of non-zero parameters also decrease.

```{r}
plot(train_lr_dummies, xvar = "lambda", label = TRUE)
```

In this plot we can see that as lambda increases the number of non-zero parameters decreases. 

```{r}
set.seed(123)
lr_cv_dummies <- cv.glmnet(x.train.dummies, as.factor(y.train.dummies), family = "binomial")
lr_cv_dummies
```

Here we can see that lambda.min is 0.005 and lambda.1se is 0.010. Let's take a look at the cross-validation curve. 

```{r}
#Plotting
plot(lr_cv_dummies)
```

In the plot we can clearly see that as lambda increases the binomial deviance first decreases a little and then increases sharply after lamba.min and lambda.1st. Also, that the number of non-zero paramaters also decreased significantly as lambda increased. Let's take a look at the coefficients of the predictive parameters and see what coefficients were eliminated from the model. 

```{r}
#Looking at Coefficients
coef(lr_cv_dummies)
```

Here are some interesting things:

  - Required experience, going to school in the US, skill level and unit of pay were all eliminated. Many countries and other categorical dummy variables were also eliminated.
  - Alternative occupation accepted, foreign language required, years since graduation, whether your currently employed, your employer completing you application, the waiting period and hour wage were all kept. 
  - Chile, Greece, Iraq, Lebanon, Mongolia, UK and the United states all had a negative impact on acceptance and Belgium, India and Japan had a positive impact.
  - The worker having education degrees including law degrees and medical degrees had a positive impact. 
  - The minimum amount of education being required to do the job being an associate's degree or less seemed to have a negative impact on approval.
  - Lastly already having an H1B visa also had a positive impact on approval

### Getting Prediction MSE and Classification Rate for Lasso

```{r}
pred_test_lr_dummies <- bind_cols(predict(lr_cv_dummies, newx = x.test.dummies, s = "lambda.1se", type="response"),
                      predict(lr_cv_dummies, newx = x.test.dummies, s = "lambda.min", type="response"))

round(colMeans((pred_test_lr_dummies-y.test.dummies)^2), digits = 2)

Predicted.lr.dummies <- ifelse(pred_test_lr_dummies >= 0.5, 1, 0)[,1]
table(H1B_dummies_Test$CASE_STATUS, Predicted.lr.dummies)

class_rate2 = (621+665)/(621+128+91+665)

1-class_rate2

```

The RMSE for LASSO regression using our data was 0.11 and the error classification rate was 14.5%

## Conclusion

Overall, the RMSE for the LASSO regression was better than the Ridge regression and I think the LASSO regression was the best out of the two because it allowed us to identify the variables that are most strongly associated with H1B Visa approval.
